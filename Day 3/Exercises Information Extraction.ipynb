{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c184b5",
   "metadata": {},
   "source": [
    "And now let's practice what we have just learnt but now with a multilingual text!\n",
    "\n",
    "Script Sources:\n",
    "\n",
    "* **NLTK**: Tsilimos, Maria. Python: Introduction to Natural Language Processing (NLP). IT Central, University of Zurich.\n",
    "* **Spacy**: https://spacy.io/usage/spacy-101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251fd040",
   "metadata": {},
   "source": [
    "# Exercise 1: replicating the NLTK IE architecture with the first chapter of Twenty Thousand Leagues Under the Sea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8584532",
   "metadata": {},
   "source": [
    "#### A. We import our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe4e928",
   "metadata": {},
   "source": [
    "The first chapter of **Vingt mille lieues sous les mers** (Twenty Thousand Leagues under the Sea) has been created for you (without being cleaned and pre-processed, yet without \\r\\n characters). Write some code to open it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6fa701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b769d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "with open(\"chapter_1_20.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0a8e9",
   "metadata": {},
   "source": [
    "#### B. We import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05deff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85955fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk import ne_chunk\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635df862",
   "metadata": {},
   "source": [
    "#### C. Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e68f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83654a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "sentences = sent_tokenize(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca402949",
   "metadata": {},
   "source": [
    "#### D. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63ce3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcdb9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "token_sentences = [word_tokenize(sentence) for sentence in sentences] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703d9ae",
   "metadata": {},
   "source": [
    "#### E. POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a30ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c16fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "pos_sentences = [nltk.pos_tag(sentence) for sentence in token_sentences ] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79554728",
   "metadata": {},
   "source": [
    "#### F. Chunking and NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a05eeb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b183f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "chunked_sentences = nltk.ne_chunk_sents(pos_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "964c322d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPE Les\n",
      "GPE En\n",
      "PERSON Les\n",
      "GPE Si\n",
      "GPE En\n",
      "GPE Burnach\n",
      "ORGANIZATION Company_\n",
      "GPE Le\n",
      "PERSON Baker\n",
      "GPE Donc\n",
      "GPE Pareil\n",
      "PERSON Pacifique\n",
      "GPE India\n",
      "GPE Pacific\n",
      "ORGANIZATION Company_\n",
      "GPE Donc\n",
      "GPE Quinze\n",
      "PERSON _Compagnie Nationale_\n",
      "GPE Greenwich\n",
      "PERSON Le\n",
      "GPE Ces\n",
      "PERSON Inman\n",
      "GPE Partout\n",
      "GPE Les\n",
      "ORGANIZATION Moby Dick\n",
      "PERSON Kraken\n",
      "PERSON Pline\n",
      "GPE Pontoppidan\n",
      "PERSON Paul Heggede\n",
      "PERSON Harrington\n",
      "PERSON La\n",
      "GPE Les\n",
      "GPE Six\n",
      "GPE Aux\n",
      "PERSON Brésil\n",
      "PERSON Berlin\n",
      "GPE Britannique\n",
      "PERSON Smithsonnienne\n",
      "GPE Washington\n",
      "ORGANIZATION _The\n",
      "GPE Indian Archipelago_\n",
      "PERSON Moigno\n",
      "PERSON Petermann\n",
      "GPE France\n",
      "GPE Ses\n",
      "PERSON Linnée\n",
      "GPE Krakens\n",
      "GPE Enfin\n",
      "PERSON Hippolyte\n",
      "GPE Pendant\n",
      "GPE Il\n",
      "GPE La\n",
      "PERSON Océan Company_\n",
      "GPE Sous\n",
      "GPE Nul\n",
      "GPE Canada\n",
      "GPE Les\n",
      "GPE Ils\n",
      "GPE Le\n",
      "GPE Ce\n",
      "GPE Seulement\n",
      "ORGANIZATION Compagnie\n",
      "GPE Personne\n",
      "PERSON Cunard\n",
      "GPE Cet\n",
      "PERSON Liverpool\n",
      "PERSON Halifax\n",
      "GPE Huit\n",
      "ORGANIZATION Compagnie\n",
      "PERSON Cunard\n",
      "GPE Ainsi\n",
      "ORGANIZATION Compagnie\n",
      "GPE Si\n",
      "GPE Nulle\n",
      "GPE Depuis\n",
      "PERSON Cunard\n",
      "GPE Aussi\n",
      "GPE France\n",
      "PERSON Cunard\n",
      "GPE Ceci\n",
      "GPE Il\n",
      "GPE Ses\n",
      "PERSON Son\n",
      "PERSON _Scotia_\n",
      "PERSON Le\n",
      "ORGANIZATION _Scotia_\n",
      "PERSON Anderson\n",
      "GPE En\n",
      "PERSON Le _Scotia_\n",
      "GPE Le\n",
      "PERSON Anderson\n",
      "GPE Il\n",
      "GPE Fort\n",
      "GPE Le\n",
      "PERSON Anderson\n",
      "GPE Il\n",
      "PERSON Clear\n",
      "PERSON Liverpool\n",
      "PERSON Les\n",
      "PERSON _Scotia_\n",
      "GPE La\n",
      "GPE Il\n",
      "GPE Tel\n",
      "GPE Depuis\n",
      "GPE Ce\n",
      "PERSON Les\n"
     ]
    }
   ],
   "source": [
    "for sent in chunked_sentences:\n",
    "    for chunk in sent: \n",
    "        if hasattr(chunk,'label'): \n",
    "            print(chunk.label(), ' '.join(c[0] for c in chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7054e34",
   "metadata": {},
   "source": [
    "#### G. Transforming that into a list and creating three different lists: 1. Person, 2. Organization, 3. GPE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c39f96b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed207da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb2e961",
   "metadata": {},
   "source": [
    "1. Creating a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff5aa2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_sentences = nltk.ne_chunk_sents(pos_sentences) #remember to always write this again! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c8adebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_entities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e950d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in chunked_sentences:\n",
    "    for chunk in sent:\n",
    "        if hasattr(chunk, \"label\"):\n",
    "            named_entities.append((chunk.label(), ' '.join(c[0] for c in chunk)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e7181bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GPE', 'Les'),\n",
       " ('GPE', 'En'),\n",
       " ('PERSON', 'Les'),\n",
       " ('GPE', 'Si'),\n",
       " ('GPE', 'En'),\n",
       " ('GPE', 'Burnach'),\n",
       " ('ORGANIZATION', 'Company_'),\n",
       " ('GPE', 'Le'),\n",
       " ('PERSON', 'Baker'),\n",
       " ('GPE', 'Donc'),\n",
       " ('GPE', 'Pareil'),\n",
       " ('PERSON', 'Pacifique'),\n",
       " ('GPE', 'India'),\n",
       " ('GPE', 'Pacific'),\n",
       " ('ORGANIZATION', 'Company_'),\n",
       " ('GPE', 'Donc'),\n",
       " ('GPE', 'Quinze'),\n",
       " ('PERSON', '_Compagnie Nationale_'),\n",
       " ('GPE', 'Greenwich'),\n",
       " ('PERSON', 'Le'),\n",
       " ('GPE', 'Ces'),\n",
       " ('PERSON', 'Inman'),\n",
       " ('GPE', 'Partout'),\n",
       " ('GPE', 'Les'),\n",
       " ('ORGANIZATION', 'Moby Dick'),\n",
       " ('PERSON', 'Kraken'),\n",
       " ('PERSON', 'Pline'),\n",
       " ('GPE', 'Pontoppidan'),\n",
       " ('PERSON', 'Paul Heggede'),\n",
       " ('PERSON', 'Harrington'),\n",
       " ('PERSON', 'La'),\n",
       " ('GPE', 'Les'),\n",
       " ('GPE', 'Six'),\n",
       " ('GPE', 'Aux'),\n",
       " ('PERSON', 'Brésil'),\n",
       " ('PERSON', 'Berlin'),\n",
       " ('GPE', 'Britannique'),\n",
       " ('PERSON', 'Smithsonnienne'),\n",
       " ('GPE', 'Washington'),\n",
       " ('ORGANIZATION', '_The'),\n",
       " ('GPE', 'Indian Archipelago_'),\n",
       " ('PERSON', 'Moigno'),\n",
       " ('PERSON', 'Petermann'),\n",
       " ('GPE', 'France'),\n",
       " ('GPE', 'Ses'),\n",
       " ('PERSON', 'Linnée'),\n",
       " ('GPE', 'Krakens'),\n",
       " ('GPE', 'Enfin'),\n",
       " ('PERSON', 'Hippolyte'),\n",
       " ('GPE', 'Pendant'),\n",
       " ('GPE', 'Il'),\n",
       " ('GPE', 'La'),\n",
       " ('PERSON', 'Océan Company_'),\n",
       " ('GPE', 'Sous'),\n",
       " ('GPE', 'Nul'),\n",
       " ('GPE', 'Canada'),\n",
       " ('GPE', 'Les'),\n",
       " ('GPE', 'Ils'),\n",
       " ('GPE', 'Le'),\n",
       " ('GPE', 'Ce'),\n",
       " ('GPE', 'Seulement'),\n",
       " ('ORGANIZATION', 'Compagnie'),\n",
       " ('GPE', 'Personne'),\n",
       " ('PERSON', 'Cunard'),\n",
       " ('GPE', 'Cet'),\n",
       " ('PERSON', 'Liverpool'),\n",
       " ('PERSON', 'Halifax'),\n",
       " ('GPE', 'Huit'),\n",
       " ('ORGANIZATION', 'Compagnie'),\n",
       " ('PERSON', 'Cunard'),\n",
       " ('GPE', 'Ainsi'),\n",
       " ('ORGANIZATION', 'Compagnie'),\n",
       " ('GPE', 'Si'),\n",
       " ('GPE', 'Nulle'),\n",
       " ('GPE', 'Depuis'),\n",
       " ('PERSON', 'Cunard'),\n",
       " ('GPE', 'Aussi'),\n",
       " ('GPE', 'France'),\n",
       " ('PERSON', 'Cunard'),\n",
       " ('GPE', 'Ceci'),\n",
       " ('GPE', 'Il'),\n",
       " ('GPE', 'Ses'),\n",
       " ('PERSON', 'Son'),\n",
       " ('PERSON', '_Scotia_'),\n",
       " ('PERSON', 'Le'),\n",
       " ('ORGANIZATION', '_Scotia_'),\n",
       " ('PERSON', 'Anderson'),\n",
       " ('GPE', 'En'),\n",
       " ('PERSON', 'Le _Scotia_'),\n",
       " ('GPE', 'Le'),\n",
       " ('PERSON', 'Anderson'),\n",
       " ('GPE', 'Il'),\n",
       " ('GPE', 'Fort'),\n",
       " ('GPE', 'Le'),\n",
       " ('PERSON', 'Anderson'),\n",
       " ('GPE', 'Il'),\n",
       " ('PERSON', 'Clear'),\n",
       " ('PERSON', 'Liverpool'),\n",
       " ('PERSON', 'Les'),\n",
       " ('PERSON', '_Scotia_'),\n",
       " ('GPE', 'La'),\n",
       " ('GPE', 'Il'),\n",
       " ('GPE', 'Tel'),\n",
       " ('GPE', 'Depuis'),\n",
       " ('GPE', 'Ce'),\n",
       " ('PERSON', 'Les')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d7085b",
   "metadata": {},
   "source": [
    "2. Creating a person list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b96c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = []\n",
    "\n",
    "for a,b in named_entities:\n",
    "    if a == \"PERSON\":\n",
    "        person.append([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ae58a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PERSON', 'Les'],\n",
       " ['PERSON', 'Baker'],\n",
       " ['PERSON', 'Pacifique'],\n",
       " ['PERSON', '_Compagnie Nationale_'],\n",
       " ['PERSON', 'Le'],\n",
       " ['PERSON', 'Inman'],\n",
       " ['PERSON', 'Kraken'],\n",
       " ['PERSON', 'Pline'],\n",
       " ['PERSON', 'Paul Heggede'],\n",
       " ['PERSON', 'Harrington'],\n",
       " ['PERSON', 'La'],\n",
       " ['PERSON', 'Brésil'],\n",
       " ['PERSON', 'Berlin'],\n",
       " ['PERSON', 'Smithsonnienne'],\n",
       " ['PERSON', 'Moigno'],\n",
       " ['PERSON', 'Petermann'],\n",
       " ['PERSON', 'Linnée'],\n",
       " ['PERSON', 'Hippolyte'],\n",
       " ['PERSON', 'Océan Company_'],\n",
       " ['PERSON', 'Cunard'],\n",
       " ['PERSON', 'Liverpool'],\n",
       " ['PERSON', 'Halifax'],\n",
       " ['PERSON', 'Cunard'],\n",
       " ['PERSON', 'Cunard'],\n",
       " ['PERSON', 'Cunard'],\n",
       " ['PERSON', 'Son'],\n",
       " ['PERSON', '_Scotia_'],\n",
       " ['PERSON', 'Le'],\n",
       " ['PERSON', 'Anderson'],\n",
       " ['PERSON', 'Le _Scotia_'],\n",
       " ['PERSON', 'Anderson'],\n",
       " ['PERSON', 'Anderson'],\n",
       " ['PERSON', 'Clear'],\n",
       " ['PERSON', 'Liverpool'],\n",
       " ['PERSON', 'Les'],\n",
       " ['PERSON', '_Scotia_'],\n",
       " ['PERSON', 'Les']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8759a2",
   "metadata": {},
   "source": [
    "3. Creating a GPE list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd0ea5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPE = []\n",
    "\n",
    "for a,b in named_entities:\n",
    "    if a == \"GPE\":\n",
    "        GPE.append([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbe98957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['GPE', 'Les'],\n",
       " ['GPE', 'En'],\n",
       " ['GPE', 'Si'],\n",
       " ['GPE', 'En'],\n",
       " ['GPE', 'Burnach'],\n",
       " ['GPE', 'Le'],\n",
       " ['GPE', 'Donc'],\n",
       " ['GPE', 'Pareil'],\n",
       " ['GPE', 'India'],\n",
       " ['GPE', 'Pacific'],\n",
       " ['GPE', 'Donc'],\n",
       " ['GPE', 'Quinze'],\n",
       " ['GPE', 'Greenwich'],\n",
       " ['GPE', 'Ces'],\n",
       " ['GPE', 'Partout'],\n",
       " ['GPE', 'Les'],\n",
       " ['GPE', 'Pontoppidan'],\n",
       " ['GPE', 'Les'],\n",
       " ['GPE', 'Six'],\n",
       " ['GPE', 'Aux'],\n",
       " ['GPE', 'Britannique'],\n",
       " ['GPE', 'Washington'],\n",
       " ['GPE', 'Indian Archipelago_'],\n",
       " ['GPE', 'France'],\n",
       " ['GPE', 'Ses'],\n",
       " ['GPE', 'Krakens'],\n",
       " ['GPE', 'Enfin'],\n",
       " ['GPE', 'Pendant'],\n",
       " ['GPE', 'Il'],\n",
       " ['GPE', 'La'],\n",
       " ['GPE', 'Sous'],\n",
       " ['GPE', 'Nul'],\n",
       " ['GPE', 'Canada'],\n",
       " ['GPE', 'Les'],\n",
       " ['GPE', 'Ils'],\n",
       " ['GPE', 'Le'],\n",
       " ['GPE', 'Ce'],\n",
       " ['GPE', 'Seulement'],\n",
       " ['GPE', 'Personne'],\n",
       " ['GPE', 'Cet'],\n",
       " ['GPE', 'Huit'],\n",
       " ['GPE', 'Ainsi'],\n",
       " ['GPE', 'Si'],\n",
       " ['GPE', 'Nulle'],\n",
       " ['GPE', 'Depuis'],\n",
       " ['GPE', 'Aussi'],\n",
       " ['GPE', 'France'],\n",
       " ['GPE', 'Ceci'],\n",
       " ['GPE', 'Il'],\n",
       " ['GPE', 'Ses'],\n",
       " ['GPE', 'En'],\n",
       " ['GPE', 'Le'],\n",
       " ['GPE', 'Il'],\n",
       " ['GPE', 'Fort'],\n",
       " ['GPE', 'Le'],\n",
       " ['GPE', 'Il'],\n",
       " ['GPE', 'La'],\n",
       " ['GPE', 'Il'],\n",
       " ['GPE', 'Tel'],\n",
       " ['GPE', 'Depuis'],\n",
       " ['GPE', 'Ce']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001dd971",
   "metadata": {},
   "source": [
    "4. Creating an organization list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f80e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "organization = []\n",
    "\n",
    "for a,b in named_entities:\n",
    "    if a == \"ORGANIZATION\":\n",
    "        organization.append([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d91267c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ORGANIZATION', 'Company_'],\n",
       " ['ORGANIZATION', 'Company_'],\n",
       " ['ORGANIZATION', 'Moby Dick'],\n",
       " ['ORGANIZATION', '_The'],\n",
       " ['ORGANIZATION', 'Compagnie'],\n",
       " ['ORGANIZATION', 'Compagnie'],\n",
       " ['ORGANIZATION', 'Compagnie'],\n",
       " ['ORGANIZATION', '_Scotia_']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68086aa",
   "metadata": {},
   "source": [
    "We see that NLTK makes many more mistakes in here! For example, in the Person list, we see Bresil, Berlin, Liverpool or Halifax tagged wrongly (those would be GPE). Let's see if Spacy can do better! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eec074",
   "metadata": {},
   "source": [
    "# Exercise 2: Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b96532b",
   "metadata": {},
   "source": [
    "#### A. We import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "132c4a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96579693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26b1b1",
   "metadata": {},
   "source": [
    "#### B. We download the French SPACY pipeline and we inspect the entity labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce1db2f",
   "metadata": {},
   "source": [
    "You may need to do this (remove the #symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de0ce604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b9f4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ecd5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3877a037",
   "metadata": {},
   "source": [
    "You can find the information in here! (https://spacy.io/models/fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "548e5845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LOC', 'MISC', 'ORG', 'PER')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe('ner').labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54110f5",
   "metadata": {},
   "source": [
    "As so many of you may want to work with German texts, repeat the same steps but using German instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adf1a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "346b570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05bf23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "\n",
    "nlp_2 = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73b9d0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LOC', 'MISC', 'ORG', 'PER')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_2.get_pipe('ner').labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f639fc",
   "metadata": {},
   "source": [
    "So, now, because we are working with a french pipeline, the labels change. Let's focus on LOC (location), ORG (Organization) and PER (persone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f32e0",
   "metadata": {},
   "source": [
    "#### C. We initialize the NLP object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4b62016",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556708e",
   "metadata": {},
   "source": [
    "#### D. We create a list with the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed7c75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ee1214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "named_entities = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    named_entities.append([ent.text, ent.label_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "199ad9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ÉCUEIL FUYANT', 'MISC'],\n",
       " ['Europe', 'LOC'],\n",
       " ['Amérique', 'LOC'],\n",
       " ['États des deux continents', 'MISC'],\n",
       " ['Cuvier', 'PER'],\n",
       " ['Lacépède', 'PER'],\n",
       " ['M. Dumeril', 'PER'],\n",
       " ['M. de Quatrefages', 'PER'],\n",
       " ['Governor-Higginson', 'PER'],\n",
       " ['Calcutta and Burnach steam navigation Company', 'ORG'],\n",
       " ['Australie', 'LOC'],\n",
       " ['capitaine Baker', 'PER'],\n",
       " ['Governor-Higginson', 'PER'],\n",
       " ['Pareil', 'LOC'],\n",
       " ['Pacifique', 'LOC'],\n",
       " ['Cristobal-Colon', 'LOC'],\n",
       " ['West India and Pacific steam', 'ORG'],\n",
       " ['Company_. Donc', 'PER'],\n",
       " ['Governor-Higginson', 'PER'],\n",
       " ['Cristobal-Colon', 'LOC'],\n",
       " [\"l'_Helvetia\", 'LOC'],\n",
       " ['Compagnie Nationale', 'ORG'],\n",
       " ['Shannon', 'PER'],\n",
       " ['Royal-Mail', 'MISC'],\n",
       " ['Atlantique', 'LOC'],\n",
       " ['États-Unis', 'LOC'],\n",
       " ['Europe', 'LOC'],\n",
       " ['méridien de', 'LOC'],\n",
       " ['Shannon', 'PER'],\n",
       " ['îles Aléoutiennes', 'LOC'],\n",
       " ['Kulammak', 'LOC'],\n",
       " ['Umgullick', 'MISC'],\n",
       " ['Etna', 'LOC'],\n",
       " ['ligne Inman', 'LOC'],\n",
       " ['Normandie', 'LOC'],\n",
       " ['Fitz-James', 'LOC'],\n",
       " ['Lord-Clyde', 'LOC'],\n",
       " ['Angleterre', 'LOC'],\n",
       " ['Amérique', 'LOC'],\n",
       " ['Allemagne', 'LOC'],\n",
       " ['bafoua', 'LOC'],\n",
       " ['Moby Dick', 'MISC'],\n",
       " ['Kraken', 'LOC'],\n",
       " ['Océan', 'LOC'],\n",
       " ['Aristote', 'PER'],\n",
       " ['Pline', 'PER'],\n",
       " ['Pontoppidan', 'MISC'],\n",
       " ['Paul Heggede', 'PER'],\n",
       " ['M. Harrington', 'PER'],\n",
       " ['Castillan', 'MISC'],\n",
       " ['Constitutionnel_.', 'LOC'],\n",
       " ['Institut géographique', 'LOC'],\n",
       " ['Brésil', 'LOC'],\n",
       " ['Académie royale des sciences de Berlin', 'ORG'],\n",
       " ['Association Britannique', 'ORG'],\n",
       " ['Institution Smithsonnienne de Washington', 'LOC'],\n",
       " ['The Indian Archipelago', 'ORG'],\n",
       " ['Cosmos', 'MISC'],\n",
       " ['Moigno', 'PER'],\n",
       " ['Mittheilungen', 'LOC'],\n",
       " ['Petermann', 'PER'],\n",
       " ['la France', 'LOC'],\n",
       " ['Linnée', 'LOC'],\n",
       " ['Krakens', 'LOC'],\n",
       " ['Moby Dick', 'MISC'],\n",
       " ['Hippolyte', 'PER'],\n",
       " ['Moravian', 'LOC'],\n",
       " ['Montréal Océan Company', 'ORG'],\n",
       " ['Moravian', 'LOC'],\n",
       " ['Canada', 'LOC'],\n",
       " ['Océan', 'LOC'],\n",
       " ['Moravian', 'LOC'],\n",
       " ['Compagnie', 'ORG'],\n",
       " ['Cunard', 'PER'],\n",
       " ['Liverpool', 'LOC'],\n",
       " ['Halifax', 'LOC'],\n",
       " ['Compagnie', 'ORG'],\n",
       " ['Cunard', 'PER'],\n",
       " [\"l'Arabia\", 'LOC'],\n",
       " ['Persia', 'LOC'],\n",
       " ['China', 'LOC'],\n",
       " ['Scotia', 'MISC'],\n",
       " ['Java', 'MISC'],\n",
       " ['Russia', 'PER'],\n",
       " ['Great-Eastern', 'LOC'],\n",
       " ['Compagnie', 'ORG'],\n",
       " ['Cunard', 'PER'],\n",
       " ['Atlantique', 'LOC'],\n",
       " ['la France', 'LOC'],\n",
       " ['ligne Cunard', 'LOC'],\n",
       " ['Scotia', 'MISC'],\n",
       " ['Scotia', 'MISC'],\n",
       " ['Anderson', 'PER'],\n",
       " ['Scotia', 'MISC'],\n",
       " ['capitaine Anderson', 'PER'],\n",
       " ['cinquième compartiment', 'MISC'],\n",
       " ['capitaine Anderson', 'PER'],\n",
       " ['Scotia', 'MISC'],\n",
       " ['cap Clear', 'LOC'],\n",
       " ['Liverpool', 'LOC'],\n",
       " ['Compagnie', 'ORG'],\n",
       " ['Scotia', 'MISC'],\n",
       " ['Bureau-Veritas', 'ORG'],\n",
       " ['Illustration', 'MISC'],\n",
       " ['Page 6', 'LOC']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8e078",
   "metadata": {},
   "source": [
    "#### E. We create three lists: one with PER, one with LOC, one with ORG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78c09007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15a7dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "person = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\":\n",
    "        person.append([ent.text, ent.label_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9600155a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cuvier', 'PER'],\n",
       " ['Lacépède', 'PER'],\n",
       " ['M. Dumeril', 'PER'],\n",
       " ['M. de Quatrefages', 'PER'],\n",
       " ['Governor-Higginson', 'PER'],\n",
       " ['capitaine Baker', 'PER'],\n",
       " ['Governor-Higginson', 'PER'],\n",
       " ['Company_. Donc', 'PER'],\n",
       " ['Governor-Higginson', 'PER'],\n",
       " ['Shannon', 'PER'],\n",
       " ['Shannon', 'PER'],\n",
       " ['Aristote', 'PER'],\n",
       " ['Pline', 'PER'],\n",
       " ['Paul Heggede', 'PER'],\n",
       " ['M. Harrington', 'PER'],\n",
       " ['Moigno', 'PER'],\n",
       " ['Petermann', 'PER'],\n",
       " ['Hippolyte', 'PER'],\n",
       " ['Cunard', 'PER'],\n",
       " ['Cunard', 'PER'],\n",
       " ['Russia', 'PER'],\n",
       " ['Cunard', 'PER'],\n",
       " ['Anderson', 'PER'],\n",
       " ['capitaine Anderson', 'PER'],\n",
       " ['capitaine Anderson', 'PER']]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0691858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "GPE = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"LOC\":\n",
    "        GPE.append([ent.text, ent.label_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "032a78b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Europe', 'LOC'],\n",
       " ['Amérique', 'LOC'],\n",
       " ['Australie', 'LOC'],\n",
       " ['Pareil', 'LOC'],\n",
       " ['Pacifique', 'LOC'],\n",
       " ['Cristobal-Colon', 'LOC'],\n",
       " ['Cristobal-Colon', 'LOC'],\n",
       " [\"l'_Helvetia\", 'LOC'],\n",
       " ['Atlantique', 'LOC'],\n",
       " ['États-Unis', 'LOC'],\n",
       " ['Europe', 'LOC'],\n",
       " ['méridien de', 'LOC'],\n",
       " ['îles Aléoutiennes', 'LOC'],\n",
       " ['Kulammak', 'LOC'],\n",
       " ['Etna', 'LOC'],\n",
       " ['ligne Inman', 'LOC'],\n",
       " ['Normandie', 'LOC'],\n",
       " ['Fitz-James', 'LOC'],\n",
       " ['Lord-Clyde', 'LOC'],\n",
       " ['Angleterre', 'LOC'],\n",
       " ['Amérique', 'LOC'],\n",
       " ['Allemagne', 'LOC'],\n",
       " ['bafoua', 'LOC'],\n",
       " ['Kraken', 'LOC'],\n",
       " ['Océan', 'LOC'],\n",
       " ['Constitutionnel_.', 'LOC'],\n",
       " ['Institut géographique', 'LOC'],\n",
       " ['Brésil', 'LOC'],\n",
       " ['Institution Smithsonnienne de Washington', 'LOC'],\n",
       " ['Mittheilungen', 'LOC'],\n",
       " ['la France', 'LOC'],\n",
       " ['Linnée', 'LOC'],\n",
       " ['Krakens', 'LOC'],\n",
       " ['Moravian', 'LOC'],\n",
       " ['Moravian', 'LOC'],\n",
       " ['Canada', 'LOC'],\n",
       " ['Océan', 'LOC'],\n",
       " ['Moravian', 'LOC'],\n",
       " ['Liverpool', 'LOC'],\n",
       " ['Halifax', 'LOC'],\n",
       " [\"l'Arabia\", 'LOC'],\n",
       " ['Persia', 'LOC'],\n",
       " ['China', 'LOC'],\n",
       " ['Great-Eastern', 'LOC'],\n",
       " ['Atlantique', 'LOC'],\n",
       " ['la France', 'LOC'],\n",
       " ['ligne Cunard', 'LOC'],\n",
       " ['cap Clear', 'LOC'],\n",
       " ['Liverpool', 'LOC'],\n",
       " ['Page 6', 'LOC']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15932c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "org = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"ORG\":\n",
    "        org.append([ent.text, ent.label_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfcecbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Calcutta and Burnach steam navigation Company', 'ORG'],\n",
       " ['West India and Pacific steam', 'ORG'],\n",
       " ['Compagnie Nationale', 'ORG'],\n",
       " ['Académie royale des sciences de Berlin', 'ORG'],\n",
       " ['Association Britannique', 'ORG'],\n",
       " ['The Indian Archipelago', 'ORG'],\n",
       " ['Montréal Océan Company', 'ORG'],\n",
       " ['Compagnie', 'ORG'],\n",
       " ['Compagnie', 'ORG'],\n",
       " ['Compagnie', 'ORG'],\n",
       " ['Compagnie', 'ORG'],\n",
       " ['Bureau-Veritas', 'ORG']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e43f48",
   "metadata": {},
   "source": [
    "So: once again we see that Spacy really outperforms NLTK!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
